import chromadb
from chromadb.utils import embedding_functions
import os

# ================= é…ç½® =================
DATA_FOLDER = "./knowledge_data"
# âš ï¸ å…³é”®ä¿®æ”¹ï¼šæŠŠåˆ‡ç‰‡å¤§å°æ”¹å¤§ï¼
# åŸæ¥æ˜¯ 300ï¼Œç°åœ¨æ”¹æˆ 1200ã€‚
# è¿™æ ·è¶³ä»¥è¦†ç›–æˆ‘ä»¬å†™çš„ä»»ä½•ä¸€ç¯‡ txt æ–‡æ¡£ï¼Œä¿è¯â€œæ•´ç¯‡å­˜å…¥ï¼Œæ•´ç¯‡å–å‡ºâ€ã€‚
CHUNK_SIZE = 1200 
# ========================================

# 1. åˆå§‹åŒ–
chroma_client = chromadb.PersistentClient(path="./rag_db")
emb_fn = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")

# é‡å»ºé›†åˆ
try:
    chroma_client.delete_collection(name="garbage_knowledge")
    print("ğŸ—‘ï¸ å·²æ¸…ç©ºæ—§çŸ¥è¯†åº“...")
except:
    pass
collection = chroma_client.create_collection(name="garbage_knowledge", embedding_function=emb_fn)

# 2. è¯»å–æ–‡ä»¶
documents = []
metadatas = []
ids = []
id_counter = 0

if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)
    exit()

files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(".txt")]
print(f"ğŸ“‚ å‘ç° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...")

for filename in files:
    filepath = os.path.join(DATA_FOLDER, filename)
    with open(filepath, 'r', encoding='utf-8') as f:
        text = f.read()
    
    # å› ä¸º CHUNK_SIZE å¾ˆå¤§ï¼Œè¿™é‡Œå®é™…ä¸Šå°±æ˜¯æŠŠæ•´ä¸ªæ–‡ä»¶å½“åšä¸€ä¸ª chunk
    for i in range(0, len(text), CHUNK_SIZE):
        chunk = text[i:i+CHUNK_SIZE]
        if len(chunk) < 10: continue 
        
        documents.append(chunk)
        metadatas.append({"source": filename})
        ids.append(f"doc_{id_counter}")
        id_counter += 1

# 3. å­˜å…¥æ•°æ®åº“
if documents:
    print(f"ğŸ§  æ­£åœ¨å­˜å…¥ {len(documents)} æ¡å®Œæ•´çŸ¥è¯†...")
    batch_size = 100
    for i in range(0, len(documents), batch_size):
        collection.add(
            documents=documents[i:i+batch_size],
            metadatas=metadatas[i:i+batch_size],
            ids=ids[i:i+batch_size]
        )
    print(f"âœ… æˆåŠŸï¼çŸ¥è¯†åº“å·²æ›´æ–°ã€‚ç°åœ¨æ¯æ¡çŸ¥è¯†éƒ½æ˜¯å®Œæ•´çš„äº†ã€‚")